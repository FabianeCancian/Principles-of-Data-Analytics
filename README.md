# Purpose
The purpose of the assessment is to ensure students can demonstrate the following.

Source and investigate sets of data.
Programmatically explore and visualize data.
Apply basic mathematical data analysis techniques to data sets.
Model real-world problems for analysis by computer.
Provide evidence in a decision-making process using a data set.
Appreciate the limitations of graphical representations in data intensive workflows.

## Overview
The assessment is broken into three overlapping components: a set of tasks, a small project, and a presentational component. All components should be submitted in a single Jupyter notebook in a single GitHub repository. 
The assessment focuses on the widely available palmerpenguins data set. The data set is interesting for several reasons.
There are four tasks to complete, listed below. The project, also below, is essentially a fifth task but is larger than the others. These should ideally be completed as we cover the relevant topics in the first few weeks of the module.
The presentational component does not involve you giving a presentation. Rather, it refers to how your work is presented in GitHub and your Jupyter notebook.

## Tasks:

1. Create a GitHub repository with a README.md and a .gitignore. Add a Jupyter notebook called penguins.ipynb and add a title to it.
2. Find the palmerpenguins data set online and load it into your Jupyter notebook. In your notebook, give an overview of the data set and the variables it contains.
3. Suggest the types of variables that should be used to model the variables in the data set in Python, explaining your rationale.
4. Create a bar chart of an appropriate variable in the data set. Then create a histogram of an appropriate variable in the data set.

## Project:
Select two variables from the data set and provide an analysis of how correlated they are.

## Presentational Component:
Ensure your repository is tidy, with no unnecessary items. Ensure your README.md and .gitignore files are appropriate. Make sure your notebook contains a single cohesive narrative about the data set.

# References:
- [Project Description](https://ianmcloughlin.github.io/2324_principles_of_data_analytics/)
- [Finding the variable types](https://www.w3schools.com/python/pandas/ref_df_dtypes.asp)
- [Plot Histograms using matplotlib](https://matplotlib.org/stable/gallery/statistics/hist.html#histograms)
- [Plot bar charts using seanborn](https://seaborn.pydata.org/generated/seaborn.barplot.html)
- [Removing NaN from the dataset](https://www.statology.org/numpy-remove-nan/)
- [Python data types](https://www.w3schools.com/python/python_datatypes.asp)
- [Numpy Object](https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.object_)